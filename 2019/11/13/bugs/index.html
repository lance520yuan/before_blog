<!DOCTYPE html>
<html lang=zh>
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="description" content="希望成为一个技术人">
  <meta name="keywords" content="">
  
    <link rel="icon" href="/favicon.ico">
  
    
  <title>web crawler基础学习之requests请求的应用 | Lanceyuanの一方天地</title>
  <link rel="stylesheet" href="/style.css">
  <link rel="stylesheet" href="/lib/jquery.fancybox.min.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
  <header>
  <div class="header-container">
    <a class='logo' href="/">
      <span>Lanceyuanの一方天地</span>
    </a>
    <ul class="right-header">
      
        <li class="nav-item">
          
            <a href="/" class="item-link">首页</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/about" class="item-link">关于</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/archives" class="item-link">归档</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/tags" class="item-link">标签</a>
          
        </li>
      
    </ul>
  </div>
</header>

  <main id='post'>
  <div class="content">
    <article>
        <section class="content markdown-body">
          <h1>web crawler基础学习之requests请求的应用</h1>
          <div class='post-meta'>
            <i class="fa fa-calendar" aria-hidden="true"></i> <time>2019/11/13</time>
            
            
              | 
                  <i class="fa fa-tag" aria-hidden="true"></i>
                
               
  <a href="/tags/#crawler" class='tag'>crawler</a>


            
          </div>
          <h2 id="requests基础教程"><a href="#requests基础教程" class="headerlink" title="requests基础教程"></a>requests基础教程</h2><p>先介绍一下为什么要写这篇博客</p>
<p>之所以用到requests请求是因为计科的课设，但是requests请求调用接口本质上并不属于爬虫，我一开始的想法是利用网络爬虫爬取豆瓣网页实现自动浏览，但是豆瓣<del>太善良了</del>，它提供了<strong>官方接口</strong>可以调用数据，这不是让我减少工作量吗？！我不</p>
<p><strong>真香</strong></p>
<p>不夸张的说，是真的香，那就让我们来看看，如何访问接口结果为自己所用。</p>
<p>首先呢，很重要的事项是，说一说我们感兴趣的信息及获取渠道和步骤</p>
<h2 id="思路简介"><a href="#思路简介" class="headerlink" title="思路简介"></a>思路简介</h2><hr>
<ol>
<li>requests请求获得json格式数据</li>
<li>对json数据进行数据清洗</li>
<li>转换为csv进行保存<blockquote>
<p>ps：如果利用爬虫可以利用xpath对下载的HTML数据进行处理，但是豆瓣的页面很显然并不是我们想的HTML这个问题的解决将在日后的进阶文章中发布</p>
</blockquote>
</li>
</ol>
<p>接下来分布进行整理工作~</p>
<h2 id="requests请求获得json格式数据"><a href="#requests请求获得json格式数据" class="headerlink" title="requests请求获得json格式数据"></a>requests请求获得json格式数据</h2><hr>
<p>访问API接口利用postman进行访问测试，利用request获取json数据<br>如果你访问官方的API接口你会发现：</p>
<p><img src="../image/2019-11-13-09-10-08.png" alt=""><br>这是什么鬼？！</p>
<p>原因是因为官方关闭了API，但是不要害怕，哪里<del>有压迫</del>哪里就有其他的民间API，我们这里选择了超级好用的反向服务器代理的API，谢谢作者大大的制作</p>
<blockquote>
<p>API文档及连接: <a href="https://douban-api.uieee.com" target="_blank" rel="noopener">https://douban-api.uieee.com</a></p>
</blockquote>
<p>这个上面有很清楚的介绍，对request了解的同学现在就可以自己研究啦，但是我们这是一篇面向新手的博客教程~所以让我们继续来讲</p>
<p>根据上述API介绍，我们发现了我们感兴趣数据存在的API：</p>
<blockquote>
<p>电影：<a href="https://douban-api.uieee.com/v2/movie/subject/电影ID" target="_blank" rel="noopener">https://douban-api.uieee.com/v2/movie/subject/电影ID</a><br>演员：<a href="https://douban-api.uieee.com/v2/movie/celebrity/演员ID" target="_blank" rel="noopener">https://douban-api.uieee.com/v2/movie/celebrity/演员ID</a></p>
</blockquote>
<p><img src="../image/2019-11-13-09-17-09.png" alt=""><br>ok 数据获取成功！接下来用requests转到字典~</p>
<p>代码逻辑很简单</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(path,num)</span>:</span><span class="comment">#path和num是路径名ID名</span></span><br><span class="line">    r=requests.get(path+num)</span><br><span class="line">    dict1=r.json()</span><br><span class="line">    <span class="keyword">return</span> dict1</span><br></pre></td></tr></table></figure>
<p>讲一下其中我不小心踩到的坑<br>如果你不小心用了r.text恭喜你，你进入了编码错误的坑<br><img src="../image/2019-11-13-09-23-07.png" alt=""></p>
<blockquote>
<p>python默认采用utf-8对中文进行编码，用text直接返回的编码不能被识别，所以一定要用json返回字典哦</p>
</blockquote>
<p>上述代码其实用的核心内容就是get指令,我们可以从官方文档上看到相关操作，为了防止官方文档因不可抗力消失，过两天我们将详细对requests学习并留档（不要问我leetcode更新到哪去了）</p>
<blockquote>
<p>参考requests文档：<a href="http://cn.python-requests.org/zh_CN/latest/" target="_blank" rel="noopener">http://cn.python-requests.org/zh_CN/latest/</a></p>
</blockquote>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><hr>
<p>数据清洗工作就相对比较繁琐了，其主要内容是提取你感兴趣的数据，这里我们主要针对如下数据进行研究</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">listone=[<span class="string">"id"</span>,<span class="string">"year"</span>,<span class="string">"title"</span>,<span class="string">"reviews_count"</span>,<span class="string">"wish_count"</span>,<span class="string">"collect_count"</span>]</span><br><span class="line">other=[<span class="string">"castsid"</span>,<span class="string">"castsname"</span>,<span class="string">"directorsid"</span>,<span class="string">"directorsname"</span>,<span class="string">"writersid"</span>,<span class="string">"writersname"</span>]</span><br><span class="line">listlist=[<span class="string">"tags"</span>,<span class="string">"pubdates"</span>,<span class="string">"languages"</span>,<span class="string">"durations"</span>,<span class="string">"genres"</span>,<span class="string">"countries"</span>,<span class="string">"summary"</span>,<span class="string">"aka"</span>]</span><br><span class="line">special=[<span class="string">"casts"</span>,<span class="string">"directors"</span>,<span class="string">"writers"</span>]</span><br><span class="line"></span><br><span class="line">listact=[<span class="string">"id"</span>,<span class="string">"name"</span>,<span class="string">"name_en"</span>,<span class="string">"gender"</span>,<span class="string">"professions"</span>,<span class="string">"summary"</span>,<span class="string">"birthday"</span>,<span class="string">"born_place"</span>]</span><br></pre></td></tr></table></figure>
<p>还是很繁琐？那你可以根据自己的需求进行调整。<br>总之，最后返回数据表格要用的字典的形式进行返回，每次访问你想找到的值都要用key:你想找到的类型  value:你获得的值</p>
<p>字典获取成功，我们就可以保存为csv文件了</p>
<h2 id="csv文件生成"><a href="#csv文件生成" class="headerlink" title="csv文件生成"></a>csv文件生成</h2><hr>
<p>这里运用的就是csv库啦，csv库做过数据可视化和数据分析的人都比较常用，是一个蛮好用的表格处理<br>核心整理思路如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">writecsv</span><span class="params">(dict1,ListMovie)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"test.csv"</span>,<span class="string">"w"</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line"></span><br><span class="line">        writer = csv.DictWriter(csvfile,ListMovie)<span class="comment">#ListMovie是列表名</span></span><br><span class="line">        <span class="comment"># writer.writeheader()#写入文件头，注意文件头写入一次就够了，文件头既是ListMovie</span></span><br><span class="line">        writer.writerow(dict1)</span><br></pre></td></tr></table></figure>
<p>到此整个API文档的利用就做完啦~<br>详细代码可参见</p>
<blockquote>
<p>github：<a href="https://github.com/lance520yuan/crawler" target="_blank" rel="noopener">https://github.com/lance520yuan/crawler</a></p>
</blockquote>
<p>欢迎下载使用哦</p>

        </section>
    </article>
    
        <!-- disqus 评论框 start -->
        <div class="comment">
            <div id="disqus_thread" class="disqus-thread">
              <i>Loading comments box needs to over the wall</i>
            </div>
        </div>
        <!-- disqus 评论框 end -->
    
    
        <!-- livere 评论框 start -->
        <div class="comment">
            <div id="lv-container" data-id="city" data-uid="your_livere_uid"></div>
        </div>
        <!-- livere 评论框 end -->
        
  </div>
  <aside>
    
    <div class="toc-container">
        <h1>目录</h1>
        <div class="content">
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#requests基础教程"><span class="toc-number">1.</span> <span class="toc-text">requests基础教程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#思路简介"><span class="toc-number">2.</span> <span class="toc-text">思路简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#requests请求获得json格式数据"><span class="toc-number">3.</span> <span class="toc-text">requests请求获得json格式数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据清洗"><span class="toc-number">4.</span> <span class="toc-text">数据清洗</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#csv文件生成"><span class="toc-number">5.</span> <span class="toc-text">csv文件生成</span></a></li></ol>
        </div>
    </div>
    
  </aside>
</main>

<!-- disqus 公共JS代码 -->
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES * * */
  var disqus_shortname = "your_disqus_shortname";
  var disqus_identifier = "lance520yuan.cn/2019/11/13/bugs/";
  var disqus_url = "lance520yuan.cn/2019/11/13/bugs/";

  isAgent(getDisqus)

  // determine user agent in China
  function isAgent(cb) {
    var url = '//graph.facebook.com/feed?callback=h';
    var xhr = new XMLHttpRequest();
    var called = false;
    xhr.open('GET', url);
    xhr.onreadystatechange = function() {
      if (xhr.readyState === 4 && xhr.status === 200) {
      called = true;
      cb(true);
      }
    };
    xhr.send();
    // timeout 1s, this facebook API is very fast.
    setTimeout(function() {
      if (!called) {
      xhr.abort();
      cb(false)
      }
    }, 1000);
  }

  function getDisqus(isAgent) {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; 
    dsq.async = true
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq)
  }
</script>
<!-- disqus 公共JS代码 end -->


<script type="text/javascript">
  (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];

      if (typeof LivereTower === 'function') { return; }

      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;

      e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script>


  <footer>
  <div class="copyright">
    <div>
      &copy; 2019 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a>&nbsp
    </div>
    <div>
      Theme by <a href="https://github.com/lewis-geek/hexo-theme-Aath" target="_blank">Aath</a>
    </div>
  </div>
</footer>


<script src="https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script src="/lib/in-view.min.js"></script>
<script src="/lib/lodash.min.js"></script>
<script>
  var isDown = true
  var oldY = 0
  inView.offset(50)

  document.body.addEventListener('touchstart', function(){});
  
  window.addEventListener('scroll', _.throttle(e => {
    var currentY = window.scrollY
    if((oldY - currentY) < 0) {
      isDown = true
    } else {
      isDown = false
    }
    oldY = currentY
  }, 250))

  $("article img").each(function() {
      var strA = "<a data-fancybox='gallery' href='" + this.src + "'></a>";
      $(this).wrapAll(strA);
  });

  $('.toc-link').each(function() {
      var href = $(this).attr("href");
      
      inView(href).on('exit', () => {
        if (isDown) {
          handleActive(href)
        }
      })

      inView(href).on('enter', () => {
        if (!isDown) {
          handleActive(href)
        }
      })

      this.onclick = function(e) {
        var pos = $(href).offset().top - 10;
        $("html,body").animate({scrollTop: pos}, 300);
        setTimeout(() => {
          handleActive(href)
        }, 350)
        return false
      }
  })

  function handleActive(href) {
    document.querySelectorAll('.toc-link').forEach(elm => {
      elm.classList.remove('active')
    })
    document.querySelector(".toc [href='"+ href +"']").classList.add('active')
  }
</script>
<script src="/lib/jquery.fancybox.min.js"></script>


</body>
</html>
